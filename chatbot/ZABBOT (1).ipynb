{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZPeBLs3M8YW",
        "outputId": "fdf55227-4fb9-4f4c-c1f2-7da4b6bb571a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index-embeddings-openai\n",
            "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-embeddings-openai)\n",
            "  Downloading llama_index_core-0.11.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting openai>=1.1.0 (from llama-index-embeddings-openai)\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.10.10)\n",
            "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.14)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.2)\n",
            "Collecting nltk>3.8.1 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.1.0->llama-index-embeddings-openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai)\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.2.0)\n",
            "Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_core-0.11.19-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dirtyjson, tenacity, nltk, mypy-extensions, marshmallow, jiter, h11, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index-core, llama-index-embeddings-openai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed dataclasses-json-0.6.7 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 llama-index-core-0.11.19 llama-index-embeddings-openai-0.2.5 marshmallow-3.23.0 mypy-extensions-1.0.0 nltk-3.9.1 openai-1.52.2 tenacity-8.5.0 tiktoken-0.8.0 typing-inspect-0.9.0\n",
            "Collecting llama-index-llms-openai\n",
            "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.7 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (0.11.19)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (1.52.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.23.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (24.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.2.0)\n",
            "Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: llama-index-llms-openai\n",
            "Successfully installed llama-index-llms-openai-0.2.16\n",
            "Collecting llama-index-readers-file\n",
            "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (4.12.3)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (0.11.19)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (2.2.2)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (24.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.2.2)\n",
            "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf, pypdf, llama-index-readers-file\n",
            "Successfully installed llama-index-readers-file-0.2.2 pypdf-4.3.1 striprtf-0.0.26\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=cdd71aa26dcc9c34e55f8d01598783dc2dc45954470f0ba230a0d4a09d085829\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "%pip install llama-index-embeddings-openai\n",
        "%pip install llama-index-llms-openai\n",
        "%pip install llama-index-readers-file\n",
        "%pip install docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DHvHhYjgoM4W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "xxiKkksdmL-w",
        "outputId": "f194c71a-b230-49d2-dedd-0c332a800288"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llama_index'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-46ecea266ed6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectorStoreIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleDirectoryReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# from llama_index.llms.openai import OpenAI\n",
        "# from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "# from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "# llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# # Initialize the embedding model using text-embedding-3-small\n",
        "# embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Settings.llm = llm\n",
        "# Settings.embed_model = embed_model\n",
        "\n",
        "# data = SimpleDirectoryReader(\n",
        "#     input_dir=\"/content/data\",\n",
        "#     required_exts=[\".pdf\"]\n",
        "# ).load_data()\n",
        "\n",
        "# index = VectorStoreIndex.from_documents(data)\n",
        "\n",
        "# query_engine = index.as_query_engine(similarity_top_k=3)\n",
        "\n",
        "# from llama_index.core.memory import ChatMemoryBuffer\n",
        "# from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
        "\n",
        "# # creating chat memory buffer\n",
        "# memory = ChatMemoryBuffer.from_defaults(token_limit=4500)\n",
        "\n",
        "# # creating chat engine\n",
        "# chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
        "#    index.as_retriever(),\n",
        "#    memory=memory,\n",
        "#    llm=llm\n",
        "# )\n",
        "\n",
        "# # generating chat response\n",
        "# response = chat_engine.chat(\n",
        "#    \"What is szabist like?\"\n",
        "# )\n",
        "# print(str(response))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGCnJyCmN180",
        "outputId": "f3e6b132-14f2-46a0-ccaf-a60dd488edbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At Szabist University, various programs are offered across different faculties. Here are some of the programs available:\n",
            "\n",
            "1. Faculty of Management Sciences:\n",
            "   - Bachelor of Business Administration (BBA)\n",
            "   - BS Business Analytics (BSBA)\n",
            "   - BS Accounting & Finance (BS A&F)\n",
            "   - BS Accounting & Finance (BS A&F 2.5 Years)\n",
            "   - Master of Business Administration (MBA)\n",
            "   - Executive Master of Business Administration (EMBA)\n",
            "   - Professional Master of Business Administration (PMBA)\n",
            "   - Masters of Human Resource Management (MHRM)\n",
            "   - Master of Project Management (MPM)\n",
            "   - MS Project Management (MS PM)\n",
            "   - MS Management Science (MS MS)\n",
            "   - MS Business Analytics (MSBA)\n",
            "   - PhD Management Science (PhD MS)\n",
            "\n",
            "2. Faculty of Computing and Engineering Sciences:\n",
            "   - BS Computer Science (BS CS)\n",
            "   - BS Software Engineering (BS SE)\n",
            "   - MS Computer Science (MS CS)\n",
            "   - MS Cyber Security (MS CYS)\n",
            "   - PhD Computing (PhD CS)\n",
            "\n",
            "These are just some of the programs offered at Szabist University. For more detailed information on each program, including specific courses and requirements, you can refer to the university's prospectus or contact the university directly for further assistance.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "# !pip install llama-index-llms-openai\n",
        "# !pip install llama-index\n",
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
        "import os\n",
        "\n",
        "\n",
        "# Initialize the language model\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Initialize the embedding model\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# Configure settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Load documents from the data directory\n",
        "data = SimpleDirectoryReader(\n",
        "    input_dir=\"/content/data\",\n",
        "    required_exts=[\".pdf\"]\n",
        ").load_data()\n",
        "\n",
        "# Create the vector store index\n",
        "index = VectorStoreIndex.from_documents(data)\n",
        "\n",
        "# Define the system prompt\n",
        "system_prompt = \"\"\"\n",
        "You are a knowledgeable and helpful assistant specialized in providing information about Szabist University. Your primary role is to guide students by answering any queries they have regarding the university. This includes information about admissions, programs, courses, campus facilities, faculty, extracurricular activities, university policies, important dates, and any other university-related topics.\n",
        "\n",
        "Provide clear, accurate, and up-to-date information in a friendly and professional manner. Use a conversational tone that is approachable and supportive. If you are unsure about an answer or if the information is not available in your data, politely inform the student and suggest they contact the university's administration for further assistance.\n",
        "\n",
        "Always ensure that your responses are in compliance with university guidelines and policies.\n",
        "\"\"\"\n",
        "\n",
        "# Create a chat memory buffer\n",
        "memory = ChatMemoryBuffer.from_defaults(token_limit=4500)\n",
        "\n",
        "# Create the chat engine with the system prompt\n",
        "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
        "    retriever=index.as_retriever(),\n",
        "    memory=memory,\n",
        "    llm=llm,\n",
        "    system_prompt=system_prompt\n",
        ")\n",
        "\n",
        "# Example query to the chatbot\n",
        "response = chat_engine.chat(\"What programs are offered at Szabist University?\")\n",
        "print(str(response))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "MpiPg5VRIden",
        "outputId": "3d8ea5cd-d487-4466-a2a3-7bb7234e1c6e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ServiceContext' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5b6214955793>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create a service context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m service_context = ServiceContext.from_defaults(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0membed_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ServiceContext' is not defined"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
        "import os\n",
        "\n",
        "# Initialize the language model\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Initialize the embedding model\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# Configure settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Define the index storage path\n",
        "index_storage_path = '/content/index.json'\n",
        "\n",
        "# Check if the index file exists\n",
        "if os.path.exists(index_storage_path):\n",
        "    # Load the index from disk\n",
        "    index = VectorStoreIndex.load_from_disk(index_storage_path)\n",
        "    print(\"Index loaded from disk.\")\n",
        "else:\n",
        "    # Load documents from the data directory\n",
        "    data = SimpleDirectoryReader(\n",
        "        input_dir=\"/content/data\",\n",
        "        required_exts=[\".pdf\"]\n",
        "    ).load_data()\n",
        "\n",
        "    # Create the vector store index\n",
        "    index = VectorStoreIndex.from_documents(data)\n",
        "\n",
        "    # Save the index to disk\n",
        "    index.save_to_disk(index_storage_path)\n",
        "    print(\"Index built and saved to disk.\")\n",
        "\n",
        "# Define the system prompt\n",
        "system_prompt = \"\"\"\n",
        "You are a knowledgeable and helpful assistant specialized in providing information about Szabist University. Your primary role is to guide students by answering any queries they have regarding the university. This includes information about admissions, programs, courses, campus facilities, faculty, extracurricular activities, university policies, important dates, and any other university-related topics.\n",
        "\n",
        "Provide clear, accurate, and up-to-date information in a friendly and professional manner. Use a conversational tone that is approachable and supportive. If you are unsure about an answer or if the information is not available in your data, politely inform the student and suggest they contact the university's administration for further assistance.\n",
        "\n",
        "Always ensure that your responses are in compliance with university guidelines and policies.\n",
        "\"\"\"\n",
        "\n",
        "# Create a chat memory buffer\n",
        "memory = ChatMemoryBuffer.from_defaults(token_limit=4500)\n",
        "\n",
        "# Create the chat engine with the system prompt\n",
        "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
        "    retriever=index.as_retriever(),\n",
        "    memory=memory,\n",
        "    llm=llm,\n",
        "    system_prompt=system_prompt\n",
        ")\n",
        "\n",
        "# Example query to the chatbot\n",
        "response = chat_engine.chat(\"What programs are offered at Szabist University?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9-IiwPoETAI"
      },
      "source": [
        "## Intent Recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGacFHmXIjBg",
        "outputId": "4ce53516-202a-44d9-b304-27a5e9b17274"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Program Inquiry\n",
            "\n",
            "The computer science program at Szabist University is known as the Bachelor of Science in Artificial Intelligence (BS(AI)) program. It is offered by the Department of Robotics and Artificial Intelligence. This comprehensive four-year program encompasses a total of 44 courses, amounting to 130 credit hours. The program covers various advanced topics in the field of Artificial Intelligence, including Machine Learning, Deep Learning, Explainable AI, Evolutionary Computing, Computer Vision, Software Engineering, and Natural Language Processing. Students are provided with internship opportunities to integrate practical experience with academic learning. The program is structured to equip students with the necessary skills and knowledge to solve complex problems in real-world settings, practice Artificial Intelligence in a socially and ethically responsible way, and prepare for lifelong learning in Artificial Intelligence and allied disciplines.\n",
            "\n",
            "If you need more specific details about the courses or any other aspect of the program, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
        "import os\n",
        "\n",
        "# Initialize the language model\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Initialize the embedding model\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# Configure settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Load documents from the data directory\n",
        "data = SimpleDirectoryReader(\n",
        "    input_dir=\"/content/data\",\n",
        "    required_exts=[\".pdf\"]\n",
        ").load_data()\n",
        "\n",
        "# Create the vector store index\n",
        "index = VectorStoreIndex.from_documents(data)\n",
        "\n",
        "# Define the intents for intent recognition\n",
        "intents = [\n",
        "    \"Program Inquiry\",\n",
        "    \"Admission Inquiry\",\n",
        "    \"Campus Facilities\",\n",
        "    \"General Information\"\n",
        "]\n",
        "\n",
        "# Modify the system prompt to include intent recognition\n",
        "system_prompt = f\"\"\"\n",
        "You are a knowledgeable and helpful assistant specialized in providing information about Szabist University.\n",
        "Your primary role is to guide students by answering any queries they have regarding the university.\n",
        "This includes information about admissions, programs, courses, campus facilities, faculty, extracurricular activities, university policies, important dates, and any other university-related topics.\n",
        "\n",
        "You are also capable of recognizing user intent based on the following categories:\n",
        "- Program Inquiry: Questions about academic programs, courses, or majors offered at the university.\n",
        "- Admission Inquiry: Questions about admission requirements, eligibility criteria, or how to apply.\n",
        "- Campus Facilities: Questions regarding university facilities such as libraries, dormitories, labs, etc.\n",
        "- General Information: Other queries that do not fall into the above categories.\n",
        "\n",
        "After receiving a query, classify the intent into one of these categories, and provide a clear and helpful response.\n",
        "\"\"\"\n",
        "\n",
        "# Create a chat memory buffer\n",
        "memory = ChatMemoryBuffer.from_defaults(token_limit=4500)\n",
        "\n",
        "# Create the chat engine with the system prompt\n",
        "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
        "    retriever=index.as_retriever(),\n",
        "    memory=memory,\n",
        "    llm=llm,\n",
        "    system_prompt=system_prompt\n",
        ")\n",
        "\n",
        "# Function to recognize intent and provide a response\n",
        "def recognize_intent_and_respond(user_input):\n",
        "    # Generate a chat response with intent recognition\n",
        "    query = f\"\"\"\n",
        "    The user input is: \"{user_input}\". Based on the input, classify the intent as one of the following:\n",
        "    - Program Inquiry\n",
        "    - Admission Inquiry\n",
        "    - Campus Facilities\n",
        "    - General Information\n",
        "    Then provide an appropriate response based on the intent.\n",
        "    \"\"\"\n",
        "\n",
        "    response = chat_engine.chat(query)\n",
        "    return str(response)\n",
        "\n",
        "# Example query to the chatbot for intent recognition\n",
        "user_input = \"Can you tell me about the computer science program?\"\n",
        "response = recognize_intent_and_respond(user_input)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohtIbgfJFUo8",
        "outputId": "9bc09894-3fa4-4fe1-a3a2-706b1e2d7efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Szabist University chatbot! Type 'exit' to end the conversation.\n",
            "\n",
            "You: whats the score of ammar bin yousaf recently?\n",
            "Bot: Ammar bin Yousaf recently scored as follows:\n",
            "- Calculus and Analytical Geometry: 85\n",
            "- English Composition and Comprehension: 90\n",
            "- Fundamentals of Programming: 88\n",
            "- Lab: Fundamentals of Programming: 92\n",
            "- Introduction to Computer Science: 87\n",
            "- Lab: Introduction to Computer Science: 90\n",
            "- Applied Physics: 84\n",
            "- Lab: Applied Physics: 89\n",
            "- Object Oriented Programming Techniques: 91\n",
            "- Lab: Object Oriented Programming Techniques: 94\n",
            "\n",
            "If you need more information or scores from other courses, feel free to ask!\n",
            "\n",
            "You: what about abdullah?\n",
            "Bot: Abdullah's recent scores are as follows:\n",
            "- Calculus and Analytical Geometry: 78\n",
            "- English Composition and Comprehension: 82\n",
            "- Fundamentals of Programming: 80\n",
            "- Lab: Fundamentals of Programming: 85\n",
            "- Introduction to Computer Science: 79\n",
            "- Lab: Introduction to Computer Science: 82\n",
            "- Applied Physics: 77\n",
            "- Lab: Applied Physics: 83\n",
            "- Object Oriented Programming Techniques: 84\n",
            "- Lab: Object Oriented Programming Techniques: 87\n",
            "\n",
            "If you have any more questions or need further details, feel free to ask!\n",
            "\n",
            "You: who is mr saad irfran in szabist?\n",
            "Bot: I'm sorry, but there is no specific information available about Mr. Saad Irfan in the provided documents. If you have any other questions or need information on a different topic, feel free to ask!\n",
            "\n",
            "You: do you know something about Dr Tazeen?\n",
            "Bot: Dr. Tazeen Athar is an Assistant Professor and the Head of the Department of Computer Sciences at SZABIST Islamabad. Her email address is dr.tazeen@szabist-isb.edu.pk. If you need more information about Dr. Tazeen or have any other questions, feel free to ask!\n",
            "\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
        "import os\n",
        "\n",
        "# Initialize the language model\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Initialize the embedding model using text-embedding-3-small\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Set LLM and embedding settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Load documents from the data directory (e.g., PDF files)\n",
        "data = SimpleDirectoryReader(\n",
        "    input_dir=\"/content/data\",\n",
        "    required_exts=[\".pdf\"]\n",
        ").load_data()\n",
        "\n",
        "# Create the vector store index from documents\n",
        "index = VectorStoreIndex.from_documents(data)\n",
        "\n",
        "# Use the index to create a query engine (retriever)\n",
        "query_engine = index.as_query_engine(similarity_top_k=3)\n",
        "\n",
        "# Creating chat memory buffer (for long-term memory)\n",
        "memory = ChatMemoryBuffer.from_defaults(token_limit=4500)\n",
        "\n",
        "# Creating chat engine with memory buffer to hold context\n",
        "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
        "   retriever=index.as_retriever(),\n",
        "   memory=memory,\n",
        "   llm=llm\n",
        ")\n",
        "\n",
        "# Function to handle the conversation in a loop\n",
        "def chatbot_conversation_loop():\n",
        "    print(\"Welcome to the Szabist University chatbot! Type 'exit' to end the conversation.\")\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_input = input(\"\\nYou: \")\n",
        "\n",
        "        # Exit the loop if the user types 'exit'\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Get the chatbot's response using the chat engine\n",
        "        response = chat_engine.chat(user_input)\n",
        "\n",
        "        # Print the chatbot's response\n",
        "        print(f\"Bot: {str(response)}\")\n",
        "\n",
        "# Start the conversation loop\n",
        "chatbot_conversation_loop()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
